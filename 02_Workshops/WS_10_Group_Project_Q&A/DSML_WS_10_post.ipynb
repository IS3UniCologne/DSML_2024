{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `DSML_WS_10` - Group Project Q&A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This week, we will use the workshop timeslot to work on the group projects. Therefore, we only have the following content in this notebook:\n",
    "\n",
    "- **Task**: Predicting electricity demand - continued\n",
    "- **Task**: Classifying breast cancer samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Task: Predicting electricity demand - continued"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the preparation task for workshop 8, you predicted **average electrical load** from **average temperature** using polynomial features with `scikit learn`. Let us continue from there by doing the following: \n",
    "\n",
    "- Load data and filter dataframe to exclude any observations with `Avg_temp` outside the range of -20 to +30 degrees.\n",
    "- Define X and y vectors, and perform train/test split.\n",
    "- Create polynomial features up to degree 50 and scale using `StandardScaler`.\n",
    "- Initialize and fit model using `LinearRegression`.\n",
    "- Initialize and fit second model with appropriate alpha using `Ridge`.\n",
    "- Initialize and fit third model with appropriate alpha using `Lasso`.\n",
    "- Initialize and fit fourth model with appropriate value for n_neighbors using `KNeighborsRegressor`.\n",
    "- Compare model performances using `mean_absolute_error` and `r2_score`.\n",
    "- **Extra task**: for each of the four models, create a scatter plot of the test data and plot the regression line on top of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "df = pd.read_csv(\"Pittsburgh_load_data.csv\")\n",
    "\n",
    "# limit data points to range -20 to 30\n",
    "df = df[(df[\"Avg_temp\"] >= -20) & (df[\"Avg_temp\"] <= 30)]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define X and y vectors\n",
    "xa = df[\"Avg_temp\"]\n",
    "ya = df[\"AVG\"]\n",
    "\n",
    "# train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(xa, ya, test_size=0.3,random_state=42)\n",
    "\n",
    "# create poly features\n",
    "poly_reg = PolynomialFeatures(degree = 50, include_bias = False)\n",
    "X_train_poly = poly_reg.fit_transform(X_train.values.reshape(-1,1))\n",
    "X_test_poly = poly_reg.transform(X_test.values.reshape(-1,1))\n",
    "\n",
    "# scale\n",
    "scaler = StandardScaler()\n",
    "X_train_poly_scaled = scaler.fit_transform(X_train_poly)\n",
    "X_test_poly_scaled = scaler.transform(X_test_poly)\n",
    "\n",
    "# initialize and fit linear model\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(X_train_poly_scaled,y_train)\n",
    "linear_model_predictions = linear_model.predict(X_test_poly_scaled)\n",
    "\n",
    "# initialize and fit ridge model\n",
    "ridge_model = Ridge(alpha = 0.1, solver = 'lsqr')\n",
    "ridge_model.fit(X_train_poly_scaled,y_train)\n",
    "ridge_model_predictions = ridge_model.predict(X_test_poly_scaled)\n",
    "\n",
    "# initialize and fit lasso model\n",
    "lasso_model = Lasso(alpha = 0.01)\n",
    "lasso_model.fit(X_train_poly_scaled,y_train)\n",
    "lasso_model_predictions = lasso_model.predict(X_test_poly_scaled)\n",
    "\n",
    "# initialize and fit knn model\n",
    "knn_model = KNeighborsRegressor(n_neighbors=25)\n",
    "knn_model.fit(X_train_poly_scaled,y_train)\n",
    "knn_model_predictions = knn_model.predict(X_test_poly_scaled)\n",
    "\n",
    "# compare model performances\n",
    "print(\"Linear model - MAE: \", mean_absolute_error(y_test, linear_model_predictions), \" R2: \", r2_score(y_test, linear_model_predictions))\n",
    "print(\"Ridge model - MAE: \", mean_absolute_error(y_test, ridge_model_predictions), \" R2: \", r2_score(y_test, ridge_model_predictions))\n",
    "print(\"Lasso model - MAE: \", mean_absolute_error(y_test, lasso_model_predictions), \" R2: \", r2_score(y_test, lasso_model_predictions))\n",
    "print(\"KNN model - MAE: \", mean_absolute_error(y_test, knn_model_predictions), \" R2: \", r2_score(y_test, knn_model_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXTRA TASK\n",
    "\n",
    "# define poly x scaled for full x range\n",
    "x_full_range = np.linspace(-20, 30, 1000)\n",
    "x_full_poly = poly_reg.transform(x_full_range.reshape(-1,1))\n",
    "x_full_poly_scaled = scaler.transform(x_full_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot linear model\n",
    "plt.figure(figsize = (8,6))\n",
    "plt.scatter(X_test, y_test, marker=\"x\")\n",
    "plt.plot(x_full_range, linear_model.predict(x_full_poly_scaled), color='C1')\n",
    "plt.xlim(-20,30)\n",
    "plt.ylim(1,2.5)\n",
    "plt.xlabel(\"Avg Temperature (째C)\")\n",
    "plt.ylabel(\"Avg Demand (GW)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot ridge model\n",
    "plt.figure(figsize = (8,6))\n",
    "plt.scatter(X_test, y_test, marker=\"x\")\n",
    "plt.plot(x_full_range, ridge_model.predict(x_full_poly_scaled), color='C1')\n",
    "plt.xlim(-20,30)\n",
    "plt.ylim(1,2.5)\n",
    "plt.xlabel(\"Avg Temperature (째C)\")\n",
    "plt.ylabel(\"Avg Demand (GW)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot lasso model\n",
    "plt.figure(figsize = (8,6))\n",
    "plt.scatter(X_test, y_test, marker=\"x\")\n",
    "plt.plot(x_full_range, lasso_model.predict(x_full_poly_scaled), color='C1')\n",
    "plt.xlim(-20,30)\n",
    "plt.ylim(1,2.5)\n",
    "plt.xlabel(\"Avg Temperature (째C)\")\n",
    "plt.ylabel(\"Avg Demand (GW)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot knn model\n",
    "plt.figure(figsize = (8,6))\n",
    "plt.scatter(X_test, y_test, marker=\"x\")\n",
    "plt.plot(x_full_range, knn_model.predict(x_full_poly_scaled), color='C1')\n",
    "plt.xlim(-20,30)\n",
    "plt.ylim(1,2.5)\n",
    "plt.xlabel(\"Avg Temperature (째C)\")\n",
    "plt.ylabel(\"Avg Demand (GW)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Task: Classifying breast cancer samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In workshop 9, we looked at the workings of relevant classification algorithms. One issue with we did not consideer was that we have trained our algorithms on the full set of available data. While this is fine for understanding how classification works in general, it is not suitable for developing predictive models (as you know by now).\n",
    "\n",
    "As a result, the classification metrics from last week's workshop are relatively meaningless as we need to evaluate on previously unseen data. \n",
    "\n",
    "**Design a proper model development routine to train a high-performing classification algorithm for the breast cancer dataset. Proceed as follows:**\n",
    "\n",
    "- Define your feature (let's continue to focus on `area_mean` and `concave points_mean`) and target sets.\n",
    "- Partition the data into training, validation and test set, and scale the input features.\n",
    "- Train a support vector machine on the training set.\n",
    "- Tweak hyperparameters (e.g., kernel) by validating on the validation set.\n",
    "- Report test metrics from the unseen test set (only look at the test set once you are finished validating your model. Do not go back and forth as this would create leakage!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "cancer_df = pd.read_csv(\"breast_cancer.csv\", index_col = \"id\")\n",
    "\n",
    "# define feature and target\n",
    "x = cancer_df[['area_mean','concave points_mean']].values\n",
    "y = cancer_df['diagnosis'].values\n",
    "\n",
    "# partition data\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3,random_state=42)\n",
    "X_train, X_hold, y_train, y_hold = train_test_split(X_train, y_train, test_size=(0.2/0.7),random_state=42)\n",
    "\n",
    "# scale input features (based on X_train)\n",
    "norm = StandardScaler()\n",
    "X_train_norm = norm.fit_transform(X_train)\n",
    "X_hold_norm = norm.transform(X_hold)\n",
    "X_test_norm = norm.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model on training set\n",
    "model_linear = SVC(kernel='linear', coef0=1.0)\n",
    "model_linear.fit(X_train_norm, y_train)\n",
    "\n",
    "# evaluate on holdout set\n",
    "holdout_predictions = model_linear.predict(X_hold_norm)\n",
    "print(\"Holdout Accuracy =\", accuracy_score(y_hold, holdout_predictions))\n",
    "print(\"Holdout Precision =\", precision_score(y_hold, holdout_predictions, pos_label=\"M\"))\n",
    "print(\"Holdout Recall =\", recall_score(y_hold, holdout_predictions, pos_label=\"M\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model on training set\n",
    "model_poly = SVC(kernel='poly', C = 100, degree=2, coef0=1.0)\n",
    "model_poly.fit(X_train_norm, y_train)\n",
    "\n",
    "# evaluate on holdout set\n",
    "holdout_predictions = model_poly.predict(X_hold_norm)\n",
    "print(\"Holdout Accuracy =\", accuracy_score(y_hold, holdout_predictions))\n",
    "print(\"Holdout Precision =\", precision_score(y_hold, holdout_predictions, pos_label=\"M\"))\n",
    "print(\"Holdout Recall =\", recall_score(y_hold, holdout_predictions, pos_label=\"M\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model on training set\n",
    "model_RBF = SVC(kernel='rbf', C = 100, coef0=1.0)\n",
    "model_RBF.fit(X_train_norm, y_train)\n",
    "\n",
    "# evaluate on holdout set\n",
    "holdout_predictions = model_RBF.predict(X_hold_norm)\n",
    "print(\"Holdout Accuracy =\", accuracy_score(y_hold, holdout_predictions))\n",
    "print(\"Holdout Precision =\", precision_score(y_hold, holdout_predictions, pos_label=\"M\"))\n",
    "print(\"Holdout Recall =\", recall_score(y_hold, holdout_predictions, pos_label=\"M\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate preferred model (SVM with polynomial kernel, d=2, C=100) on test set\n",
    "test_predictions = model_poly.predict(X_test_norm)\n",
    "print(\"Test Accuracy =\", accuracy_score(y_test, test_predictions))\n",
    "print(\"Test Precision =\", precision_score(y_test, test_predictions, pos_label=\"M\"))\n",
    "print(\"Test Recall =\", recall_score(y_test, test_predictions, pos_label=\"M\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DSML_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
